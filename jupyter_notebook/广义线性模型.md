1. 基本上所有的广义线性模型都来自于`from sklearn import linear_model`
2. 实例.coef_可以查看系数值
3. 岭回归
   - 提供了交叉验证的方法`ridge = linear_model.RidgeCV(alphas=[0.1, 1, 0.5, 0.2])`
   - fit之后提供了查看最优alpha的方法ridge.alpha_
4. lasso
   - 由于 Lasso 回归产生**稀疏模型**，因此可以用于执行**特征选择**(什么是稀疏模型？)
   - 交叉验证
     1. lassoCV
     2. lassolarsCV(基于下面将要提到的 [最小角回归](https://www.sklearncn.cn/2/#117-%E6%9C%80%E5%B0%8F%E8%A7%92%E5%9B%9E%E5%BD%92) 算法)
     - 对于具有许多线性回归的高维数据集， [`LassoCV`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV) 最常见。 然而，[`LassoLarsCV`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV) 在寻找 `alpha`参数值上更具有优势，而且如果<font color="#2DC26B">样本数量比特征数量少</font>得多**时，通常 [`LassoLarsCV`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV) 比 [`LassoCV`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV) 要快
     - `alpha` 和 SVM 的正则化参数`C` 之间的等式关系是 `alpha = 1 / C` 或者 `alpha = 1 / (n_samples * C)` ，并依赖于估计器和模型优化的确切的目标函数
5. logistic回归
   $$$$